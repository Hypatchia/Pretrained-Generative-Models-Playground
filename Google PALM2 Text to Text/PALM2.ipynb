{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q google.generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import google.generativeai as palm\n",
    "from google.api_core import client_options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get credentials from credentials.py\n",
    "from credentials import credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure PALM client\n",
    "palm.configure(\n",
    "    api_key = credentials[\"api_key\"], # API key\n",
    "    transport = \"rest\", # Use REST transport for local development\n",
    "    client_options = client_options.ClientOptions(api_endpoint=os.getenv(\"GOOGLE_API_BASE\")), # Use local API endpoint for local development\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model {'models/chat-bison-001'}\n",
      "description: Chat-optimized generative language model.\n",
      "Supported Generation Methods: ['generateMessage', 'countMessageTokens']\n",
      "Model {'models/text-bison-001'}\n",
      "description: Model targeted for text generation.\n",
      "Supported Generation Methods: ['generateText', 'countTextTokens', 'createTunedTextModel']\n",
      "Model {'models/embedding-gecko-001'}\n",
      "description: Obtain a distributed representation of a text.\n",
      "Supported Generation Methods: ['embedText', 'countTextTokens']\n"
     ]
    }
   ],
   "source": [
    "# Explore available models & their generation methods\n",
    "for model in palm.list_models():\n",
    "    print(\"Model\",{model.name})\n",
    "    print(f\"description: {model.description}\")\n",
    " \n",
    "    print(\"Supported Generation Methods:\", model.supported_generation_methods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save models that support text generation\n",
    "text_generators =    [model for model in palm.list_models() if \"generateText\" in model.supported_generation_methods]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_gen_model = text_generators[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate text\n",
    "from google.api_core import retry \n",
    "@retry.Retry(deadline=60, predicate=retry.if_exception_type(Exception))\n",
    "def generate_text(prompt, model = text_gen_model,temperature = 0.1):\n",
    "    return palm.generate_text(prompt=prompt, model=model, temperature=temperature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Show me how to use palm api\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "completion = generate_text(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## 1. Install the Palm API client library\n",
      "\n",
      "The Palm API client library is available for Node.js and Python. To install the library, run the following command:\n",
      "\n",
      "```\n",
      "npm install @palm/api\n",
      "```\n",
      "\n",
      "or\n",
      "\n",
      "```\n",
      "pip install palm-api\n",
      "```\n",
      "\n",
      "## 2. Create a Palm API client\n",
      "\n",
      "Once you have installed the library, you can create a Palm API client by calling the `createClient()` function. The `createClient()` function takes two arguments:\n",
      "\n",
      "* **apiKey:** Your Palm API key.\n",
      "* **baseURL:** The base URL of the Palm API server. The default value is `https://api.palm.com/v1`.\n",
      "\n",
      "For example, to create a Palm API client for Node.js, you would run the following code:\n",
      "\n",
      "```\n",
      "const palm = require('@palm/api');\n",
      "\n",
      "const client = palm.createClient({\n",
      "  apiKey: 'YOUR_API_KEY',\n",
      "});\n",
      "```\n",
      "\n",
      "## 3. Use the Palm API client\n",
      "\n",
      "Once you have created a Palm API client, you can use it to access the Palm API. The following code shows how to get a list of all of your devices:\n",
      "\n",
      "```\n",
      "const devices = await client.devices.list();\n",
      "\n",
      "console.log(devices);\n",
      "```\n",
      "\n",
      "For more information on how to use the Palm API client, please refer to the [Palm API documentation](https://developer.palm.com/docs/api).\n",
      "\n",
      "## 4. Troubleshooting\n",
      "\n",
      "If you are having trouble using the Palm API client, please check the following:\n",
      "\n",
      "* Make sure that you have installed the correct version of the library.\n",
      "* Make sure that you have provided your API key correctly.\n",
      "* Make sure that you are using the correct base URL.\n",
      "* Make sure that the Palm API server is running.\n",
      "\n",
      "If you are still having trouble, please contact Palm support for help.\n"
     ]
    }
   ],
   "source": [
    "print(completion.result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Show me how to use docker for my machine learning projects\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "completion = generate_text(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Based on the Idea that: 'In machine learning,there is a model centric approach and a data centric approach' generate 10 interview questions.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "completion = generate_text(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. What is the difference between a model-centric approach and a data-centric approach to machine learning?\n",
      "2. What are the advantages and disadvantages of each approach?\n",
      "3. When is it better to use a model-centric approach?\n",
      "4. When is it better to use a data-centric approach?\n",
      "5. How can you decide which approach to use for a particular problem?\n",
      "6. What are some of the challenges of using a model-centric approach?\n",
      "7. What are some of the challenges of using a data-centric approach?\n",
      "8. How can you mitigate the challenges of each approach?\n",
      "9. What are some of the latest research advances in model-centric and data-centric machine learning?\n",
      "10. What are the future trends in model-centric and data-centric machine learning?\n"
     ]
    }
   ],
   "source": [
    "print(completion.result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
